# Atari_DQN
Learning based on the deep Q-network

## Воспроизведение результатов DQN на играх Atari.

* Некоторые игры могут потребовать специфических методов(пример - Montezuma's Revenge, etc)
* Используются техники из статьи DeepMind: replay buffer, frame skip, target network.
* Во многих случаях табличные методы обучения с подкреплением не справляются с пространством действий и состояний.
* Для обобщения значений функции полезности на ненаблюдаемые состояния используется аппроксимация
* Идея заключается в том, чтобы использовать память прецедентов (replay buffer).
 
## Визуализация

[https://wandb.ai/senich17/DQN_Atari?nw=nwusersenich17]

### Дополнительно

[https://colab.research.google.com/drive/14-laEI5JlzRCThZ1U9Y-_uxURCQj3tot?usp=sharing]
